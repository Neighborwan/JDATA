{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train_featureV1.csv')\n",
    "test = pd.read_csv('../data/test_featureV1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(train.drop(['uid','label'],axis=1),label=train.label)\n",
    "dtest = lgb.Dataset(test.drop(['uid'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params =  {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "#    'metric': ('multi_logloss', 'multi_error'),\n",
    "    #'metric_freq': 100,\n",
    "    'is_training_metric': False,\n",
    "    'min_data_in_leaf': 12,\n",
    "    'num_leaves': 84,\n",
    "    'learning_rate': 0.06,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'verbosity':-1,\n",
    "#    'gpu_device_id':2,\n",
    "#    'device':'gpu'\n",
    "#    'lambda_l1': 0.001,\n",
    "#    'skip_drop': 0.95,\n",
    "#    'max_drop' : 10\n",
    "    #'lambda_l2': 0.005\n",
    "    #'num_threads': 18\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalMetric(preds,dtrain):\n",
    "    \n",
    "    label = dtrain.get_label()\n",
    "    \n",
    "    \n",
    "    pre = pd.DataFrame({'preds':preds,'label':label})\n",
    "    pre= pre.sort_values(by='preds',ascending=False)\n",
    "    \n",
    "    auc = metrics.roc_auc_score(pre.label,pre.preds)\n",
    "\n",
    "    pre.preds=pre.preds.map(lambda x: 1 if x>=0.5 else 0)\n",
    "\n",
    "    f1 = metrics.f1_score(pre.label,pre.preds)\n",
    "    \n",
    "    \n",
    "    res = 0.6*auc +0.4*f1\n",
    "    \n",
    "    return 'res',res,True\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本地CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tcv_agg's res: 0.529634 + 0.00653209\n",
      "[10]\tcv_agg's res: 0.642583 + 0.00514065\n",
      "[15]\tcv_agg's res: 0.702066 + 0.0122767\n",
      "[20]\tcv_agg's res: 0.728373 + 0.0197974\n",
      "[25]\tcv_agg's res: 0.744952 + 0.0155806\n",
      "[30]\tcv_agg's res: 0.75683 + 0.0172481\n",
      "[35]\tcv_agg's res: 0.761578 + 0.0169686\n",
      "[40]\tcv_agg's res: 0.760835 + 0.0174664\n",
      "[45]\tcv_agg's res: 0.763316 + 0.0178766\n",
      "[50]\tcv_agg's res: 0.767587 + 0.0187443\n",
      "[55]\tcv_agg's res: 0.769855 + 0.0164224\n",
      "[60]\tcv_agg's res: 0.771625 + 0.0169042\n",
      "[65]\tcv_agg's res: 0.769969 + 0.0122571\n",
      "[70]\tcv_agg's res: 0.769567 + 0.0129578\n",
      "[75]\tcv_agg's res: 0.771167 + 0.0140236\n",
      "[80]\tcv_agg's res: 0.769632 + 0.0119173\n",
      "[85]\tcv_agg's res: 0.769561 + 0.0130891\n",
      "[90]\tcv_agg's res: 0.772438 + 0.0150975\n",
      "[95]\tcv_agg's res: 0.770168 + 0.0132747\n",
      "[100]\tcv_agg's res: 0.772735 + 0.0138687\n",
      "[105]\tcv_agg's res: 0.770068 + 0.0133036\n",
      "[110]\tcv_agg's res: 0.769702 + 0.0136725\n",
      "[115]\tcv_agg's res: 0.77033 + 0.0122568\n",
      "[120]\tcv_agg's res: 0.771707 + 0.0132237\n",
      "[125]\tcv_agg's res: 0.772194 + 0.0125376\n",
      "[130]\tcv_agg's res: 0.772706 + 0.0119013\n",
      "[135]\tcv_agg's res: 0.772957 + 0.0122621\n",
      "[140]\tcv_agg's res: 0.773313 + 0.012718\n",
      "[145]\tcv_agg's res: 0.773606 + 0.0106977\n",
      "[150]\tcv_agg's res: 0.770843 + 0.0106217\n",
      "[155]\tcv_agg's res: 0.769938 + 0.00971551\n",
      "[160]\tcv_agg's res: 0.770133 + 0.00946832\n",
      "[165]\tcv_agg's res: 0.771734 + 0.0106507\n",
      "[170]\tcv_agg's res: 0.771567 + 0.0113988\n",
      "[175]\tcv_agg's res: 0.770459 + 0.0105384\n",
      "[180]\tcv_agg's res: 0.771026 + 0.0108702\n",
      "[185]\tcv_agg's res: 0.77036 + 0.0108825\n",
      "[190]\tcv_agg's res: 0.768647 + 0.010054\n",
      "[195]\tcv_agg's res: 0.768952 + 0.0105847\n",
      "[200]\tcv_agg's res: 0.770235 + 0.0100105\n",
      "[205]\tcv_agg's res: 0.769521 + 0.00968132\n",
      "[210]\tcv_agg's res: 0.770936 + 0.012557\n",
      "[215]\tcv_agg's res: 0.770634 + 0.00960404\n",
      "[220]\tcv_agg's res: 0.771015 + 0.0104245\n",
      "[225]\tcv_agg's res: 0.77122 + 0.00932629\n",
      "[230]\tcv_agg's res: 0.770536 + 0.0101719\n",
      "[235]\tcv_agg's res: 0.771673 + 0.0110487\n",
      "[240]\tcv_agg's res: 0.771467 + 0.0113438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'res-mean': [0.4847720030789191,\n",
       "  0.5157911226165955,\n",
       "  0.5224307366378161,\n",
       "  0.5285257507810651,\n",
       "  0.5296335200891972,\n",
       "  0.5540041970605484,\n",
       "  0.5839585794003117,\n",
       "  0.6083260874736881,\n",
       "  0.6235898470286084,\n",
       "  0.642583475812745,\n",
       "  0.6614482242281294,\n",
       "  0.6762946238820721,\n",
       "  0.6860214901621683,\n",
       "  0.692312013429507,\n",
       "  0.702065855453205,\n",
       "  0.7091564000814965,\n",
       "  0.7155888500333955,\n",
       "  0.7223434081182197,\n",
       "  0.7274112052082599,\n",
       "  0.7283726227930122,\n",
       "  0.7332023172977653,\n",
       "  0.735960754793413,\n",
       "  0.7373340089051105,\n",
       "  0.7411461094629029,\n",
       "  0.7449521659294254,\n",
       "  0.7492025134522232,\n",
       "  0.7522462055692717,\n",
       "  0.7535739951997803,\n",
       "  0.756261848926485,\n",
       "  0.7568304895536865,\n",
       "  0.7577409929049458,\n",
       "  0.7583197940112102,\n",
       "  0.7594878698452087,\n",
       "  0.7604478925878712,\n",
       "  0.7615777589562697,\n",
       "  0.7626411730937392,\n",
       "  0.7616461102817391,\n",
       "  0.762894558937754,\n",
       "  0.7617374908977542,\n",
       "  0.7608345467533358,\n",
       "  0.7642544669560869,\n",
       "  0.7632578119520277,\n",
       "  0.7642948763445322,\n",
       "  0.7655585827182106,\n",
       "  0.7633161448152546,\n",
       "  0.766971591617163,\n",
       "  0.7674611682948987,\n",
       "  0.7665823715221882,\n",
       "  0.766535480250817,\n",
       "  0.7675868506474761,\n",
       "  0.7677822646463257,\n",
       "  0.7701659311191674,\n",
       "  0.769156418027853,\n",
       "  0.7687025439616599,\n",
       "  0.7698547055319741,\n",
       "  0.7698130416317105,\n",
       "  0.7690695292553148,\n",
       "  0.7713457479176546,\n",
       "  0.7714356730622273,\n",
       "  0.7716249460398621,\n",
       "  0.7709672435250106,\n",
       "  0.7725775645686069,\n",
       "  0.7703830670860773,\n",
       "  0.7720014332908742,\n",
       "  0.7699693615503111,\n",
       "  0.7723133755384891,\n",
       "  0.770526822451154,\n",
       "  0.7705413038229044,\n",
       "  0.770176647718701,\n",
       "  0.7695671232947396,\n",
       "  0.7707396061580201,\n",
       "  0.7694389666424245,\n",
       "  0.7708471437399208,\n",
       "  0.770744989198297,\n",
       "  0.7711670790364197,\n",
       "  0.7708371454237518,\n",
       "  0.7712433591550404,\n",
       "  0.7703280082605409,\n",
       "  0.7707355640364376,\n",
       "  0.7696315484040218,\n",
       "  0.7694632785240813,\n",
       "  0.7692944713217873,\n",
       "  0.768653227381947,\n",
       "  0.7696105876406358,\n",
       "  0.7695605361821576,\n",
       "  0.7700465728571114,\n",
       "  0.770682000931248,\n",
       "  0.7701088563874124,\n",
       "  0.7706864252051675,\n",
       "  0.7724383243216978,\n",
       "  0.7720528561036982,\n",
       "  0.7710199330262815,\n",
       "  0.7722009357250901,\n",
       "  0.7721123261345803,\n",
       "  0.7701676294472145,\n",
       "  0.7724159151729646,\n",
       "  0.7726951146369898,\n",
       "  0.7724017167238539,\n",
       "  0.772876163874399,\n",
       "  0.7727353658366066,\n",
       "  0.7727532195979986,\n",
       "  0.7712905104758163,\n",
       "  0.7719965271979888,\n",
       "  0.7713631196950071,\n",
       "  0.7700683697867842,\n",
       "  0.7699966016740749,\n",
       "  0.7688475763005752,\n",
       "  0.7696249903900206,\n",
       "  0.7701136312041359,\n",
       "  0.7697015121181933,\n",
       "  0.7709587122587621,\n",
       "  0.7702884124591812,\n",
       "  0.7699851768123654,\n",
       "  0.7695518493772132,\n",
       "  0.7703301327425401,\n",
       "  0.7707479718580551,\n",
       "  0.769956296309218,\n",
       "  0.7703407860598367,\n",
       "  0.7703387103486555,\n",
       "  0.7717070546413588,\n",
       "  0.7724630879476525,\n",
       "  0.7714341305601224,\n",
       "  0.7726116181671686,\n",
       "  0.7718118976083886,\n",
       "  0.7721937027573329,\n",
       "  0.7741578552436271,\n",
       "  0.7734835147772547,\n",
       "  0.7723110188672037,\n",
       "  0.772651365550297,\n",
       "  0.7727060934520908,\n",
       "  0.772942975287996,\n",
       "  0.7730081801260118,\n",
       "  0.7732371505871241,\n",
       "  0.7737681036241083,\n",
       "  0.7729568367321638,\n",
       "  0.7720177074090849,\n",
       "  0.772256308831024,\n",
       "  0.7720531669278449,\n",
       "  0.774383285206541,\n",
       "  0.7733129419347868,\n",
       "  0.7739069820674699,\n",
       "  0.7747718283400188],\n",
       " 'res-stdv': [0.006397086167412573,\n",
       "  0.005930195573038038,\n",
       "  0.006168511023591455,\n",
       "  0.007048212080731441,\n",
       "  0.006532087900063455,\n",
       "  0.016856985265489215,\n",
       "  0.017282022029407096,\n",
       "  0.011936573788267301,\n",
       "  0.010212480080501242,\n",
       "  0.005140654774606161,\n",
       "  0.00922145511544739,\n",
       "  0.008307006602181855,\n",
       "  0.005315472478494802,\n",
       "  0.005129930560914679,\n",
       "  0.012276746599259656,\n",
       "  0.014361982357088934,\n",
       "  0.01830024561536475,\n",
       "  0.01715501816727763,\n",
       "  0.0201302110672654,\n",
       "  0.019797397149545166,\n",
       "  0.018068756932436317,\n",
       "  0.01892537003372739,\n",
       "  0.018460909407316105,\n",
       "  0.01700658749717601,\n",
       "  0.015580638060942236,\n",
       "  0.012798903688245076,\n",
       "  0.01499907250235295,\n",
       "  0.01690951258590868,\n",
       "  0.01610064479993704,\n",
       "  0.017248125212305045,\n",
       "  0.018777901866737452,\n",
       "  0.016534783632697208,\n",
       "  0.01802010029136593,\n",
       "  0.019290682700892552,\n",
       "  0.016968577435302484,\n",
       "  0.01798248987248292,\n",
       "  0.01754343049440855,\n",
       "  0.018029730552108037,\n",
       "  0.018205944177281847,\n",
       "  0.017466396192418722,\n",
       "  0.01582526455189444,\n",
       "  0.01571522721551368,\n",
       "  0.016834966773870433,\n",
       "  0.017675941830458293,\n",
       "  0.017876621402665587,\n",
       "  0.017628124538437265,\n",
       "  0.01763593755959971,\n",
       "  0.01660877389729365,\n",
       "  0.0143850921700985,\n",
       "  0.018744275061699837,\n",
       "  0.015607776325209585,\n",
       "  0.014835337014494923,\n",
       "  0.015776675124721452,\n",
       "  0.01522075209212216,\n",
       "  0.016422424909751154,\n",
       "  0.01574231733452966,\n",
       "  0.015647665582037028,\n",
       "  0.014956036616239508,\n",
       "  0.018690258506972198,\n",
       "  0.016904168012542603,\n",
       "  0.016449823327641704,\n",
       "  0.015243919000313544,\n",
       "  0.013673370847170832,\n",
       "  0.012390048271210662,\n",
       "  0.012257122559845852,\n",
       "  0.012936354663153432,\n",
       "  0.014172190212391404,\n",
       "  0.0148090051929035,\n",
       "  0.014007207936314188,\n",
       "  0.012957752540059165,\n",
       "  0.01382262428131624,\n",
       "  0.013586927225641355,\n",
       "  0.014008606610329715,\n",
       "  0.013132213426034779,\n",
       "  0.01402356412996078,\n",
       "  0.012980185128984108,\n",
       "  0.013474153763788205,\n",
       "  0.012539247434800182,\n",
       "  0.012597997132228176,\n",
       "  0.011917319884614122,\n",
       "  0.012812173512841675,\n",
       "  0.013792992180755151,\n",
       "  0.012643776024589009,\n",
       "  0.012914513021041572,\n",
       "  0.013089087233724253,\n",
       "  0.013513585469588058,\n",
       "  0.014294328946471929,\n",
       "  0.01426271348051601,\n",
       "  0.015444247842366615,\n",
       "  0.015097479266268008,\n",
       "  0.014802032630087641,\n",
       "  0.013521155787640309,\n",
       "  0.01455094487635498,\n",
       "  0.014409609449801603,\n",
       "  0.01327467890252111,\n",
       "  0.013492841360933112,\n",
       "  0.016125534888716073,\n",
       "  0.014260983045772264,\n",
       "  0.014321281120823448,\n",
       "  0.01386872489346387,\n",
       "  0.013765173748444801,\n",
       "  0.01252368287798123,\n",
       "  0.012962264207841913,\n",
       "  0.013544649425490506,\n",
       "  0.01330356980108538,\n",
       "  0.013630494701880807,\n",
       "  0.01250559005866543,\n",
       "  0.013296179397761591,\n",
       "  0.013742824648448013,\n",
       "  0.013672485682848307,\n",
       "  0.012904117137134439,\n",
       "  0.012791705103477656,\n",
       "  0.011611442545300912,\n",
       "  0.013184611033134066,\n",
       "  0.012256797422484082,\n",
       "  0.01283476527562391,\n",
       "  0.01312436812909839,\n",
       "  0.01350974352874999,\n",
       "  0.012192179408267249,\n",
       "  0.0132237181007597,\n",
       "  0.012974509333938962,\n",
       "  0.01466929554136447,\n",
       "  0.013804577037596015,\n",
       "  0.013844903195152535,\n",
       "  0.012537639598834069,\n",
       "  0.01370926589559801,\n",
       "  0.013504978529925793,\n",
       "  0.013348636938039074,\n",
       "  0.012485593053308531,\n",
       "  0.011901270112402475,\n",
       "  0.012429332843414902,\n",
       "  0.012042971401952889,\n",
       "  0.01203242146609505,\n",
       "  0.012759914056970745,\n",
       "  0.012262056821036791,\n",
       "  0.01003022574949949,\n",
       "  0.010739128907782142,\n",
       "  0.010460110212689656,\n",
       "  0.01200578137931404,\n",
       "  0.01271798088541426,\n",
       "  0.011817971045529141,\n",
       "  0.011609621226407397]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.cv(lgb_params,dtrain,feval=evalMetric,early_stopping_rounds=100,verbose_eval=5,num_boost_round=10000,nfold=3,metrics=['evalMetric'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\ttraining's res: 0.580168\n",
      "[10]\ttraining's res: 0.796436\n",
      "[15]\ttraining's res: 0.895343\n",
      "[20]\ttraining's res: 0.929084\n",
      "[25]\ttraining's res: 0.949959\n",
      "[30]\ttraining's res: 0.963436\n",
      "[35]\ttraining's res: 0.973406\n",
      "[40]\ttraining's res: 0.981669\n",
      "[45]\ttraining's res: 0.987504\n",
      "[50]\ttraining's res: 0.991184\n",
      "[55]\ttraining's res: 0.994711\n",
      "[60]\ttraining's res: 0.997056\n",
      "[65]\ttraining's res: 0.998429\n",
      "[70]\ttraining's res: 0.999329\n",
      "[75]\ttraining's res: 0.999555\n",
      "[80]\ttraining's res: 1\n",
      "[85]\ttraining's res: 1\n",
      "[90]\ttraining's res: 1\n",
      "[95]\ttraining's res: 1\n",
      "[100]\ttraining's res: 1\n",
      "[105]\ttraining's res: 1\n",
      "[110]\ttraining's res: 1\n",
      "[115]\ttraining's res: 1\n",
      "[120]\ttraining's res: 1\n",
      "[125]\ttraining's res: 1\n",
      "[130]\ttraining's res: 1\n",
      "[135]\ttraining's res: 1\n",
      "[140]\ttraining's res: 1\n",
      "[145]\ttraining's res: 1\n",
      "[150]\ttraining's res: 1\n",
      "[155]\ttraining's res: 1\n",
      "[160]\ttraining's res: 1\n",
      "[165]\ttraining's res: 1\n",
      "[170]\ttraining's res: 1\n",
      "[175]\ttraining's res: 1\n",
      "[180]\ttraining's res: 1\n",
      "[185]\ttraining's res: 1\n",
      "[190]\ttraining's res: 1\n",
      "[195]\ttraining's res: 1\n",
      "[200]\ttraining's res: 1\n",
      "[205]\ttraining's res: 1\n",
      "[210]\ttraining's res: 1\n",
      "[215]\ttraining's res: 1\n",
      "[220]\ttraining's res: 1\n",
      "[225]\ttraining's res: 1\n",
      "[230]\ttraining's res: 1\n",
      "[235]\ttraining's res: 1\n",
      "[240]\ttraining's res: 1\n",
      "[245]\ttraining's res: 1\n",
      "[250]\ttraining's res: 1\n",
      "[255]\ttraining's res: 1\n",
      "[260]\ttraining's res: 1\n",
      "[265]\ttraining's res: 1\n",
      "[270]\ttraining's res: 1\n",
      "[275]\ttraining's res: 1\n",
      "[280]\ttraining's res: 1\n",
      "[285]\ttraining's res: 1\n",
      "[290]\ttraining's res: 1\n",
      "[295]\ttraining's res: 1\n",
      "[300]\ttraining's res: 1\n"
     ]
    }
   ],
   "source": [
    "model =lgb.train(lgb_params,dtrain,feval=evalMetric,verbose_eval=5,num_boost_round=300,valid_sets=[dtrain])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(test.drop(['uid'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res =pd.DataFrame({'uid':test.uid,'label':pred})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=res.sort_values(by='label',ascending=False)\n",
    "res.label=res.label.map(lambda x: 1 if x>=0.5 else 0)\n",
    "res.label = res.label.map(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv('../result/lgb-baseline.csv',index=False,header=False,sep=',',columns=['uid','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
